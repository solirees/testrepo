harnessApiVersion: '1.0'
type: BUILD
notificationRules:
- conditions:
  - FAILED
  executionScope: WORKFLOW
  notificationGroupAsExpression: false
  userGroupAsExpression: false
  userGroupIds:
  - PFIVcv84TVW6OEpQEDvmGw
phases:
- daemonSet: false
  name: Phase 1
  phaseSteps:
  - type: PREPARE_STEPS
    name: Prepare Steps
    steps:
    - type: SHELL_SCRIPT
      name: runParallelPipelines
      properties:
        commandPath: null
        connectionAttributes: null
        delegateSelectors:
        - oli-mk-delegate-sasyuu-0
        executeOnDelegate: true
        host: null
        publishAsVar: false
        sshKeyRef: null
        sweepingOutputName: null
        sweepingOutputScope: null
        templateExpressions: null
        timeoutMillis: 600000
      templateUri: App/Harness SE/runParallelPipelines:latest
      templateVariables:
      - name: environment_list
        value: sc-client001
      - name: variable_inputs
        value: if-payment:infra-default,if-shipping:infra-default
      - name: pipeline_name
        value: Deploy App
      - name: application_name
        value: Oli-App-003
      - name: service_inputs
        value: Payment:robotshop_payment:0.5.2,Shipping:robotshop_shipping:0.5.2
      - name: account_id
        value: SAsyUUHTTImuYSZ35HPDvw
      - name: api_key
        value: U0FzeVVVSFRUSW11WVNaMzVIUER2dzo6dXhhbjQwSWs3MmdmNllCTUZuams2bEZsWmFBeFZ3TzlyRkdkY1MzbXJCVjlESkV5Zld4bDNuNzZVNFEwaDZxSk96VmZPNzZKTzI5NnJ2YjA=â€œ$
    - type: SHELL_SCRIPT
      name: runParallelPipelines2
      properties:
        commandPath: null
        connectionAttributes: null
        executeOnDelegate: true
        host: null
        outputVars: ''
        publishAsVar: false
        scriptString: "export HARNESS_ACCOUNT_ID=SAsyUUHTTImuYSZ35HPDvw\nexport HARNESS_API_KEY=U0FzeVVVSFRUSW11WVNaMzVIUER2dzo6dXhhbjQwSWs3MmdmNllCTUZuams2bEZsWmFBeFZ3TzlyRkdkY1MzbXJCVjlESkV5Zld4bDNuNzZVNFEwaDZxSk96VmZPNzZKTzI5NnJ2YjA=\n\
          export HARNESS_APPLICATION_NAME=Oli-App-003\nexport HARNESS_PIPELINE_NAME=\"\
          Deploy App\"\n\n# CSV to set list of environments to deploy to\nexport HARNESS_ENVIRONMENT_LIST=\"\
          sc-client001,sc-client002,sc-client003\"\n#export HARNESS_ENVIRONMENT_LIST=\"\
          sc-client001\"\n\n# CSV name:value (use to set infrastructure definition\
          \ names)\nexport HARNESS_VARIABLE_INPUTS='if-payment:infra-default,if-shipping:infra-default'\n\
          \n# CSV serviceName:ArtifactSourceName:buildNumber\nexport HARNESS_SERVICE_INPUTS='Payment:robotshop_payment:0.5.2,Shipping:robotshop_shipping:0.5.2'\n\
          \n# Run Python script to launch and monitor pipelines to completion\npython3\
          \ -u  << 'EOF'\n\nimport requests\nimport json\nimport os\nimport sys\n\
          import time\nimport datetime\n\nACCOUNT_ID = os.environ.get('HARNESS_ACCOUNT_ID')\n\
          API_KEY = os.environ.get('HARNESS_API_KEY')\nAPPLICATION_NAME = os.environ.get('HARNESS_APPLICATION_NAME')\n\
          PIPELINE_NAME = os.environ.get('HARNESS_PIPELINE_NAME')\nSERVICE_INPUTS\
          \ = os.environ.get('HARNESS_SERVICE_INPUTS')\nVARIABLE_INPUTS = os.environ.get('HARNESS_VARIABLE_INPUTS')\n\
          ENVIRONMENT_LIST = os.environ.get('HARNESS_ENVIRONMENT_LIST') \n\nglobal\
          \ URL\nURL = \"https://app.harness.io/gateway/api/graphql?accountId=\" +\
          \ ACCOUNT_ID\n\ndef getAppByName(appName):\n    pload = '''\n      { \n\
          \        applicationByName(name: \"%s\") { \n          id\n        }\n \
          \     } \n    ''' % (appName)\n\n    print (\"Getting Harness App ID\")\n\
          \n    response = requests.post(URL, headers={'x-api-key': API_KEY}, data=pload)\n\
          \n    json_response = response.json()\n    appId = json_response['data']['applicationByName']['id']\n\
          \    print (\"Application ID is:\" + appId)\n\n    return(appId)\n\ndef\
          \ getPipelineByName(appId, plName):\n    pload = '''\n      {\n        pipelineByName(\
          \ pipelineName: \"%s\", applicationId: \"%s\") {\n            id\n     \
          \ }\n    }\n    ''' % (plName, appId)\n\n    print (\"Getting Harness Pipeline\
          \ ID\")\n\n    response = requests.post(URL, headers={'x-api-key': API_KEY},\
          \ data=pload)\n    json_response = response.json()\n    pl_id = json_response['data']['pipelineByName']['id']\n\
          \    print (\"Pipeline ID is:\" + pl_id)\n    return(pl_id)\n\ndef launchPipeline(appId,\
          \ pipelineId, envRef, svcListRef, varListRef):\n\n    # Build list of strings\
          \ for serviceInputs\n    svcStrList = []\n    for svcRef in svcListRef:\n\
          \      svcStrList.append('{ name: \"%s\", artifactValueInput: { valueType:\
          \ BUILD_NUMBER buildNumber: { buildNumber: \"%s\" artifactSourceName: \"\
          %s\" } } }' % (svcRef['svc_name'], svcRef['build_no'], svcRef['artifact_name']))\n\
          \n    # Build list of strings for variableInputs\n    # Note: Initilise\
          \ with target environment, where ${env} is pipline template variable name\n\
          \    varStrList = [ '{ name: \"env\" variableValue: { type: NAME value:\
          \ \"%s\" } }' % (envRef['env_name']) ]\n    for varRef in varListRef:\n\
          \      varStrList.append('{ name: \"%s\" variableValue: { type: NAME value:\
          \ \"%s\" } }' % (varRef['name'], varRef['value']))\n    \n    # Set payload\n\
          \    pload = '''\n      mutation {\n        startExecution(input: {\n  \
          \        applicationId: \"%s\"\n          entityId: \"%s\"\n          executionType:\
          \ PIPELINE,\n          variableInputs: [\n            %s\n          ]\n\
          \          serviceInputs: [\n            %s\n          ]\n        }\n  \
          \      ){\n          clientMutationId\n          execution{\n          \
          \  id\n            status\n          }\n        }\n      }\n    ''' % (appId,\
          \ pipelineId, \"\\n            \".join(varStrList), \",\\n            \"\
          .join(svcStrList))\n\n    print (\"\\n--- PIPELINE EXEC REQUEST ---\")\n\
          \    print (pload)\n\n    response = requests.post(URL, headers={'x-api-key':\
          \ API_KEY}, data=pload)\n    json_response = response.json()\n\n    print\
          \ (\"--- PIPELINE EXEC RESPONSE ---\\n\")\n    print (json_response)\n\n\
          \    envRef['exec_id'] = json_response['data']['startExecution']['execution']['id']\n\
          \    envRef['exec_status'] = json_response['data']['startExecution']['execution']['status']\n\
          \n    # Initial status\n    print ('%s: %s' % (envRef['env_name'], envRef['exec_status']))\n\
          \ndef getExecStatus(execId):\n    pload = '''\n      { \n        execution(executionId:\
          \ \"%s\") { \n          status\n        }\n      } \n    ''' % (execId)\n\
          \n    response = requests.post(URL, headers={'x-api-key': API_KEY}, data=pload)\n\
          \    json_response = response.json()\n    execStatus = json_response['data']['execution']['status']\n\
          \    return(execStatus)\n\n### Start of Main ###\n\nDEFAULT='__default__'\n\
          \n# List of hashes to track status\nenvList=[]\n\n# List of hashes for service\
          \ inputs\nsvcList=[]\n\n# List of hashes for variable inputs\nvarList=[]\n\
          \napp_id = getAppByName(APPLICATION_NAME)\npl_id = getPipelineByName(app_id,\
          \ PIPELINE_NAME)\n\n# Extract service inputs into list\nfor s in (SERVICE_INPUTS.split(',')):\n\
          \  arr=s.split(':')\n  svcList.append({'svc_name': arr[0], 'artifact_name':\
          \ arr[1], 'build_no': arr[2]})\n\n# Extract variable inputs into list\n\
          for v in (VARIABLE_INPUTS.split(',')):\n  arr=v.split(':')\n  varList.append({'name':\
          \ arr[0], 'value': arr[1]})\n\n# Launch pipelines (just take first service\
          \ for now)\nfor env in (ENVIRONMENT_LIST.split(',')):\n  n=len(envList)\n\
          \  envList.append({'env_name': env, 'exec_id': DEFAULT, 'exec_status': DEFAULT})\n\
          \  launchPipeline(app_id, pl_id, envList[n], svcList, varList)\n\n# Number\
          \ of pipelines launched\nnTotal = len(envList)\nIN_PROGRESS_STATES = ['RUNNING',\
          \ 'PAUSED']\n\n# Loop to completion\nresult={}\nnDone = 0\n\nwhile (1):\n\
          \  for ref in (envList):\n    curStatus = getExecStatus(ref['exec_id'])\n\
          \    if curStatus != ref['exec_status']:\n\n      #\_Updated status for\
          \ this pipeline\n      ref['exec_status'] = curStatus\n      print ('%s:\
          \ %s' % (ref['env_name'], ref['exec_status']))\n\n      if curStatus not\
          \ in IN_PROGRESS_STATES:\n        # Job has finished\n        if curStatus\
          \ not in result.keys():\n          # Initialise\n          result[curStatus]\
          \ = 0;\n\n        # Increment count for this status\n        result[curStatus]\
          \ += 1\n\n        # Track number of finished pipeline\n        nDone +=\
          \ 1\n\n  if nDone == nTotal:\n     summary = 'Summary (%s pipelines):' %\
          \ (nTotal)\n     for key in result:\n       summary += ' %s=%s' % (key,\
          \ result[key])\n     print (summary)\n     exit(0)\n\n  time.sleep(10)\n\
          \nsys.exit(0)\n\nEOF\n\nexit $?"
        scriptType: BASH
        sshKeyRef: null
        sweepingOutputName: null
        sweepingOutputScope: null
        templateExpressions: null
        templateVariables: ''
        timeoutMillis: 600000
    stepsInParallel: false
  - type: COLLECT_ARTIFACT
    name: Collect Artifact
    stepsInParallel: false
  - type: WRAP_UP
    name: Wrap Up
    stepsInParallel: false
  provisionNodes: false
  statefulSet: false
templatized: true
userVariables:
- type: TEXT
  fixed: false
  mandatory: true
  name: env_list
  value: sc-client001,sc-client002
